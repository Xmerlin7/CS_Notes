# Explanation
- By chopping the address space into small, fixed-sized units (i.e., pages), [[Introduction to Paging|paging]] requires a large amount of mapping information.
- Because that mapping information is generally stored in physical memory, paging logically requires an extra memory lookup for each virtual address generated by the program.
- Going to memory for translation information before every instruction fetch or explicit load or store is prohibitively slow.
- To speed address translation, we are going to add what is called a **translation-lookaside buffer**, **TLB**, or **address-translation cache**.
- A TLB is part of the chip’s **memory-management unit (MMU)**, and is simply a hardware **cache** of popular virtual-to-physical address translations.
- Upon each virtual memory reference, the hardware first checks the TLB to see if the desired translation is held therein; if so, the translation is performed quickly.
##### TLB Basic Algorithm
- The TLB, like all caches, is built on the premise that in the common case, translations are found in the cache (i.e., are hits).
- If so, little overhead is added, as the TLB is found near the processing core and is designed to be quite fast.
- When a miss occurs, the high cost of paging is incurred; the page table must be accessed to find the translation (and update TLB),and an extra memory reference (or more, with more complex page tables) results.
- TLBs rely upon both **spatial** and **temporal locality** for success.
	- Temporal locality is the quick re-referencing of memory items in time.
	- With spatial locality, the idea is that if a program accesses memory at address x, it will likely soon access memory near x.
##### Who Handles The TLB Miss?
- In the olden days, the hardware(CISC) would handle the TLB miss entirely.
	- To do this, the hardware has to know exactly where the page tables are located in memory via a **page-table base register (PTBR)**, as well as their exact format.
	- The hardware would “walk” the page table, find the correct page-table entry and extract the desired translation, update the TLB with the translation, and retry the instruction.
- More modern architectures(RISC) have what is known as a **software-managed TLB**.
	- On a TLB miss, the hardware simply raises an exception, which pauses the current instruction stream, raises the privilege level to kernel mode, and jumps to a **trap handler**.
	- The return-from-trap instruction needs to be a little different than the return-from-trap we saw before when servicing a system call.
	- The return-from-trap should resume execution at the instruction after the trap into the OS, just as a return from a procedure call returns to the instruction immediately following the call into the procedure.
	- In the former case, when returning from a TLB miss-handling trap, the hardware must resume execution at the instruction that caused the trap.
	- this retry thus lets the instruction run again, this time resulting in a **TLB hit**.
- when running the TLB miss-handling code, the OS needs to be extra careful not to cause an infinite chain of TLB misses to occur.
	- OS could keep TLB miss handlers in physical memory (where they are **unmapped** and not subject to address translation). 
	- Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself.
- The primary advantage of the software-managed approach is flexibility: 
	- The OS can use any data structure it wants to implement the page table, without necessitating hardware change.
- The hardware doesn’t do much on a miss:
	- Just raise an exception and let the OS TLB miss handler do the rest.
- A TLB valid bit refers to whether a TLB entry has a valid translation within it.
	- When a system boots, for example, a common initial state for each TLB entry is to be set to invalid, because no address translations are yet cached there.
	- Once virtual memory is enabled, and once programs start running and accessing their virtual address spaces, the TLB is slowly populated, and thus valid entries soon fill the TLB.
- The TLB valid bit is quite useful when performing a context switch.
	- By setting all TLB entries to invalid, the system can ensure that the about-to-be-run process does not accidentally use a virtual-to-physical translation from a previous process.
##### TLB Contents: What’s In There?
- A typical TLB might have 32, 64, or 128 entries and be what is called **fully associa-tive**. 
- Basically, this just means that any given translation can be anywhere in the TLB, and that the hardware will search the entire TLB in parallel to find the desired translation.
- VPN and PFN are present in each entry.
- TLB commonly has a valid bit, which says whether the entry has a valid translation or not. 
- Also common are protection bits, which determine how a page can be accessed (as in the page table).
	- For example, code pages might be marked read and execute, whereas heap pages might be marked read and write.
##### TLB Issue: Context Switches
- The TLB contains virtual-to-physical translations that are only valid for the currently running process; these translations are not meaningful for other processes.
- As a result, when switching from one process to another, the hardware or OS (or both) must be careful to ensure that the about-to-be-run process does not accidentally use translations from some previously run process.
- There are a number of possible solutions to this problem:
	1. One approach is to simply **flush** the TLB on context switches, thus emptying it before running the next process.
		- However, there is a cost: each time a process runs, it must incur TLB misses as it touches its data and code pages. If the OS switches between processes frequently, this cost may be high. 
	2. To reduce this overhead, some systems add hardware support to enable sharing of the TLB across context switches. In particular, some hardware systems provide an **address space identifier (ASID)** field in the TLB.
			![[TLB.png]]
		- This solution support _code sharing_ Sharing of code pages (in binaries, or shared libraries) is useful as it reduces the number of physical pages in use, thus reducing memory overheads.
##### Issue: Replacement Policy
- There are a number of possible solutions to **cache replacement** problem:
	- One common approach is to evict the **least-recently-used** or **LRU** entry.
	- Another typical approach is to use a **random** policy, which evicts a TLB mapping at random.
# Sources
- Operating Systems: Three Easy Pieces - Chapter 19.
- [Lecture 4 - part 3](https://youtu.be/LprKOBsALGA)